\documentclass[margin,line,pifont,palatino,courier, 9pt]{res}

\usepackage{pifont}
\usepackage[latin1] {inputenc}
\topmargin -.5in
\oddsidemargin -.35in      % Reduce left margin
\evensidemargin -.35in     % Reduce right margin for even pages (if any)
\textwidth=5.75in 
\textheight=9.5in 
\usepackage{hyperref}
\usepackage[svgnames]{xcolor} 
\usepackage{fancyhdr}
\usepackage{setspace}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\fancyhf{}
\hypersetup{
colorlinks=true, % Set to true to color the text of the links and false to create colored boxes around the text
linkcolor=blue,  % Color for internal links
filecolor=magenta, % Color for URLs which open local files
urlcolor=violet    % Color for URL links
}
\linespread{1} 

\begin{document}

\name{Benjamin S. Manning \vspace*{.05in}}
\begin{resume}


\normalsize


\section{\sc Contact}
bmanning (at) mit.edu $\diamond$ \href{https://benjaminmanning.io/}{benjaminmanning.io}

\section{\sc Education}
{\bf Massachusetts Institute of Technology}\\
Ph.D. Management Science, Information Technology \hfill 2022 - Present\\
S.M., Management Research \hfill 2024\vspace{2mm}\\
{\bf Harvard University}\\
M.P.P. Economic \& Social Policy \hfill 2021\vspace{2mm}\\
{\bf Washington University in St. Louis}\\
B.A. Mathematics (College Honors) \hfill 2017

\section{\sc References}
\vspace{.15cm}
\begin{tabular}{@{}p{2.6in}p{2.75in}}
John J. Horton (Chair)& Christopher Norio Avery\\
MIT Sloan School of Management & Harvard Kennedy School \\
jjhorton (at) mit.edu & christopher\_avery (at) hks.harvard.edu\\\\
Siddharth Suri & \\
Microsoft Research & \\
suri (at) microsoft.com & \\
\end{tabular}

\section{\sc Grants (\$310,000)}
\href{https://www.mercatus.org/emergent-ventures}{Emergent Ventures Fast Grant} (\$50,000) \hfill 2025 \\
\href{https://computing.mit.edu/research/mit-generative-ai-impact-consortium/}{MIT Generative AI Impact Consortium} \& \href{https://openai.com/}{OpenAI} (\$150,000) (w/ John J. Horton) \hfill 2025 \\
\href{https://www.schmidtsciences.org/ai-at-work/}{Schmidt Sciences AI at Work Award} (\$10,000) (w/ Gili Rusak \& John J. Horton) \hfill 2025 \\
\href{https://www.mercatus.org/emergent-ventures}{Emergent Ventures Fast Grant} (\$50,000) \hfill 2024 

\section{\sc Awards \& Scholarships}
Harvard Distinction in Student Teaching Award \hfill 2025 \\
\href{https://bfi.uchicago.edu/events/event/2025-price-theory-summer-camp/}{Becker Friedman Institute Price Theory Summer Camp} \hfill 2025 \\
\href{https://thekf.org/scholarship/tuition-scholarships/tuition-scholarships-for-graduate-studies/}{Kosciuszko Foundation Tuition Scholarship} (\$6,500) \hfill 2019 \& 2022 


% \section{\sc Job Market Paper}


\section{\sc Working Papers}

\href{https://benjaminmanning.io/files/optimize.pdf}{General Social Agents}\\
(\textbf{Benjamin S. Manning}\footnote{Indicates first author or co-first authors} \& John J. Horton)\\
\textit{Under Review}

% \begin{singlespace}
% \footnotesize
% \textbf{Abstract: }
% Useful social science theories predict behavior across settings. 
% However, applying a theory to make predictions in new settings is challenging: rarely can it be done without ad hoc modifications to account for setting-specific factors.
% We argue that AI agents put in simulations of those novel settings offer an alternative for applying theory, requiring minimal or no modifications.
% We present an approach for building such ``general'' agents that use theory-grounded natural language instructions, existing empirical data, and knowledge acquired by the underlying AI during training.
% To demonstrate the approach in settings where no data from that data-generating process exists---as is often the case in applied prediction problems---we design a heterogeneous population of 883,320 novel games.
% AI agents are constructed using human data from a small set of conceptually related but structurally distinct ``seed'' games.
% In preregistered experiments, on average, agents predict initial human play in a random sample of 1,500 games from the population better than (i) a cognitive hierarchy model, (ii) game-theoretic equilibria, and (iii) out-of-the-box agents.
% For a small set of separate novel games, these simulations predict responses from a new sample of human subjects \emph{better} even than the most plausibly relevant published human data.
% \end{singlespace}

\href{https://www.nber.org/papers/w32381}{Automated Social Science: Language Models as Scientist and Subjects}\\
(\textbf{Benjamin S. Manning}\footnotemark[\value{footnote}], Kehang Zhu\footnotemark[\value{footnote}], \& John J. Horton)\\
Reject \& Resubmit at \textit{The Quarterly Journal of Economics}

% \begin{singlespace}
% \footnotesize
% \textbf{Abstract: }We present an approach for automatically generating and testing, \emph{in silico}, social scientific hypotheses.
% This automation is made possible by recent advances in large language models (LLM), but the key feature of the approach is the use of structural causal models. 
% Structural causal models provide a language to state hypotheses, a blueprint for constructing LLM-based agents, an experimental design, and a plan for data analysis.
% The fitted structural causal model becomes an object available for prediction or the planning of follow-on experiments.
% We demonstrate the approach with several scenarios: a negotiation, a bail hearing, a job interview, and an auction.
% In each case, causal relationships are both proposed and tested by the system, finding evidence for some and not others.
% We provide evidence that the insights from these simulations of social interactions are not available to the LLM purely through direct elicitation.
% When given its proposed structural causal model for each scenario, the LLM is good at predicting the signs of estimated effects, but it cannot reliably predict the magnitudes of those estimates.
% In the auction experiment, the \emph{in silico} simulation results closely match the predictions of auction theory, but elicited predictions of the clearing prices from the LLM are inaccurate.
% However, the LLM's predictions are dramatically improved if the model can condition on the fitted structural causal model.
% In short, the LLM knows more than it can (immediately) tell. 
% \end{singlespace}

\href{https://arxiv.org/abs/2407.14333}{Prompt Adaptation as a Dynamic Complement in Generative AI Systems}\\
(Eaman Jahani\footnotemark[\value{footnote}], \textbf{Benjamin S. Manning}, Joe Zhang, Hong-Yi TuYe, Mohammed Alsobay, Christos Nicolaides, Siddharth Suri, \& David Holtz)\\
Revise \& Resubmit at \textit{Information Systems Research}

% \begin{singlespace}
% \footnotesize
% \textbf{Abstract: }As generative AI systems rapidly improve, a key question emerges: How do users keep up---and what happens if they fail to do so. 
% Drawing on theories of dynamic capabilities and IT complements, we examine \textit{prompt adaptation}---the adjustments users make to their inputs in response to evolving model behavior---as a mechanism that helps determine whether technical advances translate into realized economic value. 
% In a preregistered online experiment with 1,893 participants, who submitted over 18,000 prompts and generated more than 300,000 images, users attempted to replicate a target image in 10 tries using one of three randomly assigned models: DALL-E 2, DALL-E 3, or DALL-E 3 with automated prompt rewriting. 
% We find that users with access to DALL-E 3 achieved higher image similarity than those with DALL-E 2---but only about half of this gain (51\%) came from the model itself. 
% The other half (49\%) resulted from users adapting their prompts in response to the model's capabilities. 
% This adaptation emerged across the skill distribution, was driven by trial-and-error, and could not be replicated by automated prompt rewriting, which erased 58\% of the performance improvement associated with DALL-E 3. Our findings position prompt adaptation as a dynamic complement to generative AI---and suggest that without it, a substantial share of the economic value created when models advance may go unrealized.
% \end{singlespace}

\href{https://www.nber.org/papers/w31122}{Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?}\\
(John J. Horton\footnotemark[\value{footnote}], Apostolos Filippas\footnotemark[\value{footnote}], \textbf{Benjamin S. Manning}\footnotemark[\value{footnote}])\\
Revise \& Resubmit at \textit{The Review of Economics and Statistics}\\
Extended abstract at \textit{ACM Conference on Economics \& Computation}, 2024

% \begin{singlespace}
% \footnotesize
% \textbf{Abstract: } Newly-developed large language models (LLM)---because of how they are trained and designed---are implicit computational models of humans---a \emph{homo silicus}.
% LLMs can be used like economists use \emph{homo economicus}: they can be given endowments, information, preferences, and so on, and then their behavior can be explored in scenarios via simulation.
% Experiments using this approach, derived from Charness and Rabin (2002), Kahneman et al. (1986), Samuelson and Zeckhauser (1988), Oprea (2024), and Horton (2025), show qualitatively similar results to the original, and when they differ, it is often generative for future research.
% We discuss potential applications and conceptual issues with this approach.
% \end{singlespace}

\href{https://conference.nber.org/conf_papers/f227499.pdf}{The Coasean Singularity? Demand, Supply, and Market Design with AI Agents}\\
(Peyman Shahidi\footnotemark[\value{footnote}], Gili Rusak\footnotemark[\value{footnote}], \textbf{Benjamin S. Manning}\footnotemark[\value{footnote}], Andrey Fradkin\footnotemark[\value{footnote}], \& John J. Horton\footnotemark[\value{footnote}])\\
\textit{Working Paper for NBER Economics of Transformative AI: a Research Agenda}

% \begin{singlespace}
% \footnotesize
% \textbf{Abstract: }This paper examines the transformative economic implications of AI agents---autonomous software systems that can perceive, reason, and act in digital environments to achieve goals on behalf of human principals. 
% We focus on their role as market participants, capable of executing tasks such as search, negotiation, and communication, and of transacting directly in digital marketplaces. 
% Demand for AI agents is a form of derived demand, that will be shaped by agent quality, industry context, and users' trade-offs between decision quality and effort reduction. 
% On the supply side, firms will compete to design, deploy, and monetize agents, and how this competition interacts with platform governance. At the market level, we highlight both efficiency gains through reduced transaction costs and efficiency losses through increased frictions. 
% AI agents expand the frontier of feasible market design by reducing the costs of preference elicitation, contract enforcement, and identity verification, while simultaneously raising novel regulatory challenges around bias, privacy, and consumer protection. 
% These factors create many opportunities for impactful economics research.
% \end{singlespace}

\href{https://arxiv.org/abs/2509.09071}{Strategic Tradeoffs Between Humans and AI in Multi-Agent Bargaining}\\
(Crystal Qian\footnotemark[\value{footnote}], Kehang Zhu\footnotemark[\value{footnote}],  John J. Horton, \textbf{Benjamin S. Manning}, Vivian Tsai, James Wexler, \& Nithum Thain )\\
\textit{Under Review}

% \begin{singlespace}
% \footnotesize
% \textbf{Abstract: }Coordination tasks traditionally performed by humans are increasingly being delegated to autonomous agents. As this pattern progresses, it becomes critical to evaluate not only these agents' performance but also the processes through which they negotiate in dynamic, multi-agent environments. Furthermore, different agents exhibit distinct advantages: traditional statistical agents, such as Bayesian models, may excel under well-specified conditions, whereas large language models (LLMs) can generalize across contexts. In this work, we compare humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in a dynamic negotiation setting that enables direct, identical-condition comparisons across populations, capturing both outcomes and behavioral dynamics. Bayesian agents extract the highest surplus through aggressive optimization, at the cost of frequent trade rejections. Humans and LLMs can achieve similar overall surplus, but through distinct behaviors: LLMs favor conservative, concessionary trades with few rejections, while humans employ more strategic, risk-taking, and fairness-oriented behaviors. Thus, we find that performance parity---a common benchmark in agent evaluation---can conceal fundamental differences in process and alignment, which are critical for practical deployment in real-world coordination tasks.
% \end{singlespace}

\section{\sc Publications}
\href{https://www.pnas.org/doi/10.1073/pnas.2418616122}{National Megastudy Shows that Email Nudges to Elementary School Teachers Boost Student Math Achievement, Particularly When Personalized}\\
(Angela L. Duckworth\footnotemark[\value{footnote}], Katherine L. Milkman, ... \textbf{Benjamin S. Manning}, ..., \& 26 others)\\
\textit{Proceedings of the National Academy of Sciences,} 2025

\href{https://journals.sagepub.com/doi/full/10.1177/09637214241268222}{Effect Size Magnification: No Variable is as Important as the One You're Thinking About---While You're Thinking About It}\\
(Linnea Gandhi\footnotemark[\value{footnote}], \textbf{Benjamin S. Manning}, \& Angela Duckworth)\\
\textit{Current Directions in Psychological Science,} 2024

\section{\sc In Progress}

AI Agents Can Enable Superior Market Designs\\
(Gili Rusak\footnotemark[\value{footnote}], \textbf{Benjamin S. Manning}\footnotemark[\value{footnote}], \& John J. Horton)

Recapitulating all of Experimental Economics with AI Agents\\
(\textbf{Benjamin S. Manning}\footnotemark[\value{footnote}] \& John J. Horton\footnotemark[\value{footnote}])

\section{\sc Invited\\Talks\footnotemark}
\footnotetext{Includes scheduled talks}
\textbf{2026:} 
Chapman University Brownbag Seminar;
AEA Annual Meeting;\vspace{2mm}\\
\textbf{2025:} 
Workshop on Information Systems and Economics (WISE);
Dartmouth Economics Seminar;
North American Meeting of the Economic Science Association (ESA);
Instacart Economics Team Seminar;
NYU Workshop on AI and the Future of Collaborative Innovation;
KOF ETH Zurich and IZA Workshop: Matching Workers and Jobs Online;
Machine Learning in Economics Summer Conference (MLESC25);
Academy of Management (AOM) Annual Meeting;
International Conference on Computational Social Science (IC2S2);
ZEW Conference on the Economics of ICT\footnote{Co-author presenting joint work.};
Wharton AI and the Future of Work Conference;
AI, Mechanism Design and Human Behavior: Experiments and Theory NBER/CEME Decentralization Conference;
Khipu Latin American Meeting in AI;
Artificially Intelligent Social Science Workshop (Oxford);
AEA Annual Meeting;\vspace{2mm}\\
\textbf{2024:} Workshop on Information Systems and Economics (WISE)\footnotemark[\value{footnote}];
Conference on AI, Machine Learning, and Business Analytics;
NABE Tech Economics Conference; 
Informs Annual Meeting\footnotemark[\value{footnote}];
Machine Learning in Science Conference;
Econometric Society Interdisciplinary Frontiers Conference on Economics and AI+ML; 
International Conference on Computational Social Science (IC2S2)\footnotemark[\value{footnote}];
NBER Summer Institute---Digital Economics and AI\footnotemark[\value{footnote}];
ZEW Conference on the Economics of ICT;
International Conference of the French Association of Experimental Economics;
Instacart Economics Team Seminar;
Statistical Conference in E-Commerce Research (SCECR):
Wharton AI and the Future of Work Conference; 
International Meeting on Experimental and Behavioral Social Sciences;
MIT IDE Annual Conference; 
Microsoft Research AI, Cognition, and the Economy Workshop; 
Measuring Development: AI, the Next Generation at the World Bank; 
\vspace{2mm}\\
\textbf{2023:} Interactive Causal Learning Conference; 
MIT CODE; 
MIT CSAIL's FutureTech Seminar;
Talking to Machines AI Workshop at Oxford University

\section{\sc Teaching}
\textit{QSTBA 830}: Business Experimentation and Causal Methods, \textbf{Guest Lecturer for Andrey Fradkin}---Boston University, Spring 2025

\textit{BUSN 38802}: Managerial Decision Making; \textbf{TA for Richard Thaler}, University of Chicago---Booth London Campus, Fall 2024 (Rating: 4.7/5.0)

\textit{API-101Z}: Markets and Failures; \textbf{TA for Christopher Avery}---Harvard University, Spring 2022 (Rating: 4.6/5.0)

\textit{API-101Z}: Markets and Failures; \textbf{TA for Christopher Avery}---Harvard University, Fall 2023 (Rating: 4.3/5.0)

\section{\sc Affiliations}
\href{https://ide.mit.edu/}{MIT Initiative on the Digital Economy}, \href{https://heterodoxacademy.org/}{Heterodox Academy}

\section{\sc Professional Service}
\textit{Management Science, Southern Economic Journal, Conference on Neural Information Processing Systems (NeurIPS), Conference on Digital Experimentation (CODE), ACM-Collective Intelligence, International Conference on Information Systems (ICIS), Sociological Science, International Conference on Computational Social Science (IC2S2)}

\section{\sc Employment}
\textbf{University of Pennsylvania} \hfill 2021 - 2022 \\
Research Assistant for Angela Duckworth and Colin Camerer \vspace{2mm}\\
\textbf{University of Chicago} \hfill 2020 - 2022\\
Research Assistant for Jon Rogowski \vspace{2mm}\\
\textbf{Dartmouth College} \hfill 2018 - 2019 \\
Research Assistant for Sydney Finkelstein \vspace{2mm}\\
\textbf{Phetpittayakom School} \hfill 2017 - 2018 \\
High School Math Teacher in Thailand \vspace{2mm}\\ 
\textbf{Optiver US LLC} \hfill 2016 \\
Execution Trading Intern

\end{resume}
\end{document}
